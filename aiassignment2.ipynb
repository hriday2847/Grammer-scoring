{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_submission = pd.read_csv('submission.csv')\ndf_submission","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install openai-whisper\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1. Imports\nimport os\nimport numpy as np\nimport pandas as pd\nimport librosa\nimport whisper\nimport xgboost as xgb\nfrom scipy.stats import pearsonr, skew\nfrom sklearn.metrics import mean_squared_error\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# 2. Paths\ntrain_df = pd.read_csv(\"/kaggle/input/shl-intern-hiring-assessment/dataset/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/shl-intern-hiring-assessment/dataset/test.csv\")\nsample_submission = pd.read_csv(\"/kaggle/input/shl-intern-hiring-assessment/dataset/sample_submission.csv\")\n\ntrain_path = \"/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/\"\ntest_path = \"/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/\"\n\n# 3. Whisper Embeddings + MFCC Extraction\ndef extract_features(df, audio_path, model):\n    features = []\n    for fname in tqdm(df['filename']):\n        path = os.path.join(audio_path, fname)\n        y, sr = librosa.load(path, sr=16000)\n\n        # MFCC stats\n        mfcc = librosa.feature.mfcc(y=y, sr=16000, n_mfcc=13)\n        mfcc_mean = np.mean(mfcc, axis=1)\n        mfcc_std = np.std(mfcc, axis=1)\n        mfcc_skew = skew(mfcc, axis=1)\n\n        # Whisper embeddings (we use the encoder output from tiny or base model)\n        audio = whisper.load_audio(path)\n        audio = whisper.pad_or_trim(audio)\n        mel = whisper.log_mel_spectrogram(audio).to(model.device)\n        with torch.no_grad():\n            embedding = model.encoder(mel.unsqueeze(0))  # shape: (1, frames, dim)\n            whisper_feat = embedding[0].mean(dim=0).cpu().numpy()\n\n        # Combine\n        feature_vector = np.hstack([mfcc_mean, mfcc_std, mfcc_skew, whisper_feat])\n        features.append(feature_vector)\n\n    return np.array(features)\n\n# 4. Load Whisper Model\nimport torch\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nwhisper_model = whisper.load_model(\"base\", device=device)  # You can try \"small\" or \"medium\"\n\n# 5. Extract Features\nX_train = extract_features(train_df, train_path, whisper_model)\ny_train = train_df[\"label\"].values\nX_test = extract_features(test_df, test_path, whisper_model)\n\n# 6. Handle NaN/Inf\nfor arr in [X_train, X_test]:\n    arr[np.isnan(arr)] = 0\n    arr[np.isinf(arr)] = 0\n\n# 7. XGBoost Regressor\nxgb_model = xgb.XGBRegressor(\n    n_estimators=200,\n    max_depth=6,\n    learning_rate=0.05,\n    subsample=0.9,\n    colsample_bytree=0.9,\n    random_state=42,\n    n_jobs=-1\n)\nxgb_model.fit(X_train, y_train)\n\n# 8. Evaluation\ny_pred_train = xgb_model.predict(X_train)\npearson_corr = pearsonr(y_train, y_pred_train)[0]\nrmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\nprint(f\"‚úÖ Pearson Correlation (Train): {pearson_corr:.4f}\")\nprint(f\"‚úÖ RMSE (Train): {rmse:.4f}\")\n\n# 9. Visualizations\nplt.figure(figsize=(8, 5))\nsns.scatterplot(x=y_train, y=y_pred_train)\nplt.xlabel(\"Actual Grammar Score\")\nplt.ylabel(\"Predicted Score\")\nplt.title(\"Predicted vs Actual (Train)\")\nplt.grid(True)\nplt.show()\n\nresiduals = y_train - y_pred_train\nplt.figure(figsize=(8, 4))\nsns.histplot(residuals, kde=True)\nplt.title(\"Residuals Distribution\")\nplt.xlabel(\"Residuals\")\nplt.grid(True)\nplt.show()\n\n# 10. Test Prediction\ntest_preds = xgb_model.predict(X_test)\nsample_submission[\"label\"] = test_preds\nsample_submission.to_csv(\"submission_whisper_xgb.csv\", index=False)\nprint(\"üìÅ Submission saved as submission_whisper_xgb.csv\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}